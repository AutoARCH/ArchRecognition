{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/.local/share/virtualenvs/ArchRecognition-VDW7_LdE/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from google_images_download import google_images_download\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "import numpy as np\n",
    "import glob\n",
    "import turicreate as tc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_download_images(keywords, num_images=40):\n",
    "\n",
    "    response = google_images_download.googleimagesdownload() \n",
    "\n",
    "    arguments = {\n",
    "        \"keywords\": keywords,\n",
    "        \"limit\": num_images,\n",
    "        \"print_urls\": True,\n",
    "        \"prefix_keywords\": 'azure',\n",
    "        \"suffix_keywords\": 'icon',\n",
    "        \"format\": 'png'\n",
    "    }\n",
    "    absolute_image_paths = response.download(arguments)\n",
    "\n",
    "    with open('./image_urls', 'w+') as image_urls_file:\n",
    "        for k, v in absolute_image_paths.items():\n",
    "            image_urls_file.write(k)\n",
    "            image_urls_file.write('=' * 80)\n",
    "            image_urls_file.writelines(list(absolute_image_paths.values()).join('\\n\\r'))\n",
    "            \n",
    "    return absolute_image_paths\n",
    "\n",
    "search_and_download_images('database,virtual machine,webapp,file storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('./downloads/**/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('../data/images/Whiteboard2arm-data-resized/20180723_021702377_iOS.jpg')\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height=300)\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 100, 50, 50)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imwrite('./proccessed.png', inverted_edged)\n",
    "\n",
    "# cv2.imshow(\"Inverted Edge\", inverted_edged)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.threshold(image, gray, 0, 255.0, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imwrite('./dilated.png', dilation)\n",
    "# element = cv2.getStructuringElement(Imgproc.MORPH_RECT, 7, 7)\n",
    "# cv2.dilate(grayImg, grayImg2, element);\n",
    "# cv2.erode(grayImg2, grayImg, element);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test+4'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import quote_plus\n",
    "\n",
    "quote_plus('Test 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_path_image(img_path, verbose=False):\n",
    "    if verbose:\n",
    "        print(img_path)\n",
    "    image = cv2.imread(img_path)\n",
    "    image = imutils.resize(image, height=500)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 75, 125)\n",
    "    \n",
    "    # Dilate to combine close edges into one line\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    dilated = cv2.dilate(edged, kernel, iterations=1)\n",
    "\n",
    "    # Invert edge detection to get black lines on white background (whiteboard representative)\n",
    "    inverted_edged = cv2.bitwise_not(dilated)\n",
    "    \n",
    "    \n",
    "    edge_path = img_path[:-4] + '-processed.png'\n",
    "    \n",
    "    cv2.imwrite(edge_path, inverted_edged)\n",
    "    \n",
    "    \n",
    "create_edge_path_image('../data/images/Whiteboard2arm-data-resized/20180723_024505078_iOS.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for png_path in glob.glob('./images/*.jpeg'):\n",
    "    create_edge_path_image(png_path)\n",
    "    \n",
    "    \n",
    "# [{'coordinates': {'height': 104, 'width': 110, 'x': 115, 'y': 216},\n",
    "#   'label': 'ball'},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86.3, 102.1] [665, 102.1] [665, 339.8] [86.3, 339.8]\n",
      "20180723_024521307_iOS.jpg\n",
      "[251.5, 45.2] [562.9, 45.2] [562.9, 297.8] [251.5, 297.8]\n",
      "20180723_024512276_iOS.jpg\n",
      "[38, 47] [355, 47] [355, 377] [38, 377]\n",
      "20180723_021708849_iOS.jpg\n",
      "[92, 73] [281, 73] [281, 311] [92, 311]\n",
      "20180723_021702377_iOS.jpg\n",
      "[392.5, 42.1] [599.7, 42.1] [599.7, 264.1] [392.5, 264.1]\n",
      "[170.4, 155.7] [320.9, 155.7] [320.9, 341.9] [170.4, 341.9]\n",
      "[41, 240.9] [119.9, 240.9] [119.9, 328.3] [41, 328.3]\n",
      "20180723_024439726_iOS.jpg\n",
      "[127.3, 131.5] [279.9, 131.5] [279.9, 349.3] [127.3, 349.3]\n",
      "[335.6, 42.1] [436.6, 42.1] [436.6, 158.9] [335.6, 158.9]\n",
      "[377.7, 216.7] [580.8, 216.7] [580.8, 447.2] [377.7, 447.2]\n",
      "20180723_022618958_iOS.jpg\n",
      "[293.6, 87.3] [460.8, 87.3] [460.8, 318.8] [293.6, 318.8]\n",
      "20180723_024539975_iOS.jpg\n",
      "[69, 108] [148, 108] [148, 198] [69, 198]\n",
      "[105, 236] [247, 236] [247, 385] [105, 385]\n",
      "[303, 265] [383, 265] [383, 362] [303, 362]\n",
      "20180723_021705068_iOS.jpg\n",
      "[233.6, 143.1] [473.5, 143.1] [473.5, 404] [233.6, 404]\n",
      "20180723_024531838_iOS.jpg\n",
      "[193.6, 25.3] [538.7, 25.3] [538.7, 474.5] [193.6, 474.5]\n",
      "20180723_024501745_iOS.jpg\n",
      "[258.8, 193.6] [447.2, 193.6] [447.2, 394.6] [258.8, 394.6]\n",
      "20180723_024450922_iOS.jpg\n",
      "[210.4, 91.5] [467.2, 91.5] [467.2, 419.8] [210.4, 419.8]\n",
      "20180723_022635236_iOS.jpg\n",
      "[209.4, 24.2] [293.6, 24.2] [293.6, 91.5] [209.4, 91.5]\n",
      "[110.5, 126.3] [230.4, 126.3] [230.4, 234.6] [110.5, 234.6]\n",
      "[270.4, 118.9] [357.7, 118.9] [357.7, 232.5] [270.4, 232.5]\n",
      "[386.1, 107.3] [481.9, 107.3] [481.9, 217.8] [386.1, 217.8]\n",
      "[68.4, 289.3] [130.5, 289.3] [130.5, 366.1] [68.4, 366.1]\n",
      "[189.4, 279.9] [252.5, 279.9] [252.5, 349.3] [189.4, 349.3]\n",
      "[322, 253.6] [390.3, 253.6] [390.3, 320.9] [322, 320.9]\n",
      "[451.4, 222] [514.5, 222] [514.5, 282] [451.4, 282]\n",
      "[464, 331.4] [526.1, 331.4] [526.1, 398.8] [464, 398.8]\n",
      "[394.6, 360.9] [439.8, 360.9] [439.8, 412.4] [394.6, 412.4]\n",
      "[353.5, 384] [378.8, 384] [378.8, 412.4] [353.5, 412.4]\n",
      "[311.4, 371.4] [328.3, 371.4] [328.3, 393.5] [311.4, 393.5]\n",
      "[237.8, 393.5] [265.1, 393.5] [265.1, 423] [237.8, 423]\n",
      "[96.8, 34.7] [161, 34.7] [161, 92.6] [96.8, 92.6]\n",
      "20180723_024433494_iOS.jpg\n",
      "[208.3, 94.7] [576.6, 94.7] [576.6, 396.7] [208.3, 396.7]\n",
      "20180723_024507610_iOS.jpg\n",
      "[98, 184] [282, 184] [282, 369] [98, 369]\n",
      "20180723_021711073_iOS.jpg\n",
      "[154.7, 65.2] [522.9, 65.2] [522.9, 408.2] [154.7, 408.2]\n",
      "20180723_024458662_iOS.jpg\n",
      "[290.4, 158.9] [502.9, 158.9] [502.9, 396.7] [290.4, 396.7]\n",
      "20180723_024454147_iOS.jpg\n",
      "[203.1, 92.6] [511.3, 92.6] [511.3, 456.6] [203.1, 456.6]\n",
      "20180723_022633161_iOS.jpg\n",
      "[265.1, 65.2] [486.1, 65.2] [486.1, 406.1] [265.1, 406.1]\n",
      "20180723_024526040_iOS.jpg\n",
      "[295.7, 262] [379.8, 262] [379.8, 358.8] [295.7, 358.8]\n",
      "[555.5, 189.4] [615.5, 189.4] [615.5, 255.7] [555.5, 255.7]\n",
      "20180723_024446765_iOS.jpg\n",
      "[130.5, 29.5] [522.9, 29.5] [522.9, 493.5] [130.5, 493.5]\n",
      "20180723_024505078_iOS.jpg\n",
      "[62.1, 117.8] [641.8, 117.8] [641.8, 358.8] [62.1, 358.8]\n",
      "20180723_024522624_iOS.jpg\n",
      "[419.8, 179.9] [553.4, 179.9] [553.4, 323] [419.8, 323]\n",
      "[290.4, 250.4] [370.4, 250.4] [370.4, 328.3] [290.4, 328.3]\n",
      "[163.1, 208.3] [214.6, 208.3] [214.6, 268.3] [163.1, 268.3]\n",
      "20180723_024443099_iOS.jpg\n",
      "[134.7, 41] [539.8, 41] [539.8, 482.9] [134.7, 482.9]\n",
      "20180723_022627262_iOS.jpg\n",
      "[228.3, 144.1] [444, 144.1] [444, 426.1] [228.3, 426.1]\n",
      "20180723_022624105_iOS.jpg\n",
      "[226.2, 55.8] [560.8, 55.8] [560.8, 492.4] [226.2, 492.4]\n",
      "20180723_022621760_iOS.jpg\n",
      "[40, 25.3] [168.3, 25.3] [168.3, 227.3] [40, 227.3]\n",
      "[390.3, 117.8] [547.1, 117.8] [547.1, 269.4] [390.3, 269.4]\n",
      "[101, 303] [206.2, 303] [206.2, 441.9] [101, 441.9]\n",
      "20180723_024529456_iOS.jpg\n",
      "[107.3, 93.6] [205.2, 93.6] [205.2, 252.5] [107.3, 252.5]\n",
      "[369.3, 78.9] [256.7, 78.9] [256.7, 262] [369.3, 262]\n",
      "[521.9, 264.1] [385.1, 264.1] [385.1, 67.3] [521.9, 67.3]\n",
      "20180723_024544353_iOS.jpg\n",
      "[310.4, 106.3] [650.2, 106.3] [650.2, 431.4] [310.4, 431.4]\n",
      "20180723_024516259_iOS.jpg\n",
      "[143.1, 92.6] [467.2, 92.6] [467.2, 386.1] [143.1, 386.1]\n",
      "20180723_024518216_iOS.jpg\n"
     ]
    }
   ],
   "source": [
    "tc_object_detect_images = []\n",
    "tc_object_detect_annotations = []\n",
    "\n",
    "with open('./annotations/2/wb2arm_images_2.jsonl') as annotations_file:\n",
    "    for line in annotations_file:\n",
    "        annotations = json.loads(line)\n",
    "        if annotations['answer'] == 'accept':\n",
    "            boxes = annotations['spans']\n",
    "            \n",
    "#             print(annotations)\n",
    "            object_detection_boxes_out = []\n",
    "            for box in boxes:\n",
    "\n",
    "                points = box['points']\n",
    "                top_left, bottom_left, bottom_right, top_right = points\n",
    "                print(top_left, top_right, bottom_right, bottom_left)\n",
    "                width = float(top_right[0] - top_left[0])\n",
    "                height = float(bottom_left[1] - top_left[1])\n",
    "                x_center = float(top_left[0] + (width / 2))\n",
    "                y_center = float(top_left[1] + (height / 2))\n",
    "\n",
    "                object_detection_boxes_out.append({\n",
    "                    'label': box['label'],\n",
    "                    'coordinates': {\n",
    "                        'height': height,\n",
    "                        'width': width,\n",
    "                        'x': x_center,\n",
    "                        'y': y_center\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "            print(annotations['meta']['file'])\n",
    "            tc_object_detect_images.append(annotations['meta']['file'])\n",
    "            tc_object_detect_annotations.append(object_detection_boxes_out)\n",
    "            \n",
    "            \n",
    "annotations_sf = tc.SFrame({'filename': tc_object_detect_images, 'annotations': tc_object_detect_annotations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/Whiteboard2arm-data-resized/20180723_024521307_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024512276_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_021708849_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_021702377_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024439726_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_022618958_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024539975_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_021705068_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024531838_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024501745_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024450922_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_022635236_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024433494_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024507610_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_021711073_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024458662_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024454147_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_022633161_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024526040_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024446765_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024505078_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024522624_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024443099_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_022627262_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_022624105_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_022621760_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024529456_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024544353_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024516259_iOS.jpg\n",
      "./images/Whiteboard2arm-data-resized/20180723_024518216_iOS.jpg\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob('./images/Whiteboard2arm-data/*'):\n",
    "    image = cv2.imread(path)\n",
    "    try:\n",
    "        \n",
    "        image = imutils.resize(image, height=500)\n",
    "\n",
    "        filename = path.split('/')[-1]\n",
    "        path = '/'.join(path.split('/')[:-2]) + '/Whiteboard2arm-data-resized/'\n",
    "        print(path + filename)\n",
    "        cv2.imwrite(path + filename, image)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tc.image_analysis.load_images('./images/Whiteboard2arm-data-resized/', recursive=True)\n",
    "images['filename'] = images['path'].apply(lambda s: s.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">annotations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 375</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 375</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 375</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 375</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 666</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 666</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 666</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 666</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 666</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;SQL_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 500 Width: 666</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[{&#x27;label&#x27;:<br>&#x27;DOCUMENT_DATABASE&#x27;, ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[30 rows x 2 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\timage\tImage\n",
       "\tannotations\tlist\n",
       "\n",
       "Rows: 30\n",
       "\n",
       "Data:\n",
       "+------------------------+-------------------------------+\n",
       "|         image          |          annotations          |\n",
       "+------------------------+-------------------------------+\n",
       "| Height: 500 Width: 375 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 375 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 375 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 375 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 666 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 666 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 666 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 666 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 666 | [{'label': 'SQL_DATABASE',... |\n",
       "| Height: 500 Width: 666 | [{'label': 'DOCUMENT_DATAB... |\n",
       "+------------------------+-------------------------------+\n",
       "[30 rows x 2 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_object_detect_data = images.join(annotations_sf, on='filename')[['image', 'annotations']]\n",
    "tc_object_detect_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tc_object_detect_data.random_split(0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Materializing SFrame...</pre>"
      ],
      "text/plain": [
       "Materializing SFrame..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Done.</pre>"
      ],
      "text/plain": [
       "Done."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'image' as feature column\n",
      "Using 'annotations' as annotations column\n",
      "2018-07-22 23:52:58  Training    1/1000  Loss  8.086\n",
      "2018-07-22 23:53:17  Training    3/1000  Loss  8.201\n",
      "2018-07-22 23:53:37  Training    5/1000  Loss  8.220\n",
      "2018-07-22 23:53:56  Training    7/1000  Loss  8.215\n",
      "2018-07-22 23:54:16  Training    9/1000  Loss  8.246\n",
      "2018-07-22 23:54:35  Training   11/1000  Loss  8.223\n",
      "2018-07-22 23:54:54  Training   13/1000  Loss  8.050\n",
      "2018-07-22 23:55:14  Training   15/1000  Loss  7.968\n",
      "2018-07-22 23:55:34  Training   17/1000  Loss  7.790\n",
      "2018-07-22 23:55:54  Training   19/1000  Loss  7.588\n",
      "2018-07-22 23:56:04  Training   20/1000  Loss  7.471\n",
      "2018-07-22 23:56:24  Training   22/1000  Loss  7.191\n",
      "2018-07-22 23:56:44  Training   24/1000  Loss  6.907\n",
      "2018-07-22 23:57:04  Training   26/1000  Loss  6.623\n",
      "2018-07-22 23:57:14  Training   27/1000  Loss  6.449\n",
      "2018-07-22 23:57:24  Training   28/1000  Loss  6.287\n",
      "2018-07-22 23:57:34  Training   29/1000  Loss  6.162\n",
      "2018-07-22 23:57:54  Training   31/1000  Loss  6.050\n",
      "2018-07-22 23:58:14  Training   33/1000  Loss  5.785\n",
      "2018-07-22 23:58:34  Training   35/1000  Loss  5.601\n",
      "2018-07-22 23:58:44  Training   36/1000  Loss  5.502\n",
      "2018-07-22 23:59:04  Training   38/1000  Loss  5.280\n",
      "2018-07-22 23:59:14  Training   39/1000  Loss  5.179\n",
      "2018-07-22 23:59:24  Training   40/1000  Loss  5.118\n",
      "2018-07-22 23:59:35  Training   41/1000  Loss  5.056\n",
      "2018-07-22 23:59:45  Training   42/1000  Loss  5.000\n",
      "2018-07-23 00:00:05  Training   44/1000  Loss  4.868\n",
      "2018-07-23 00:00:25  Training   46/1000  Loss  4.766\n",
      "2018-07-23 00:00:46  Training   48/1000  Loss  4.600\n",
      "2018-07-23 00:01:06  Training   50/1000  Loss  4.432\n",
      "2018-07-23 00:01:16  Training   51/1000  Loss  4.373\n",
      "2018-07-23 00:01:27  Training   52/1000  Loss  4.329\n",
      "2018-07-23 00:01:37  Training   53/1000  Loss  4.237\n",
      "2018-07-23 00:01:48  Training   54/1000  Loss  4.227\n",
      "2018-07-23 00:01:58  Training   55/1000  Loss  4.186\n",
      "2018-07-23 00:02:18  Training   57/1000  Loss  4.043\n",
      "2018-07-23 00:02:38  Training   59/1000  Loss  3.987\n",
      "2018-07-23 00:02:58  Training   61/1000  Loss  3.898\n",
      "2018-07-23 00:03:17  Training   63/1000  Loss  3.810\n",
      "2018-07-23 00:03:35  Training   65/1000  Loss  3.688\n",
      "2018-07-23 00:03:54  Training   67/1000  Loss  3.617\n",
      "2018-07-23 00:04:13  Training   69/1000  Loss  3.521\n",
      "2018-07-23 00:04:32  Training   71/1000  Loss  3.434\n",
      "2018-07-23 00:04:51  Training   73/1000  Loss  3.422\n",
      "2018-07-23 00:05:11  Training   75/1000  Loss  3.398\n",
      "2018-07-23 00:05:30  Training   77/1000  Loss  3.349\n",
      "2018-07-23 00:05:49  Training   79/1000  Loss  3.282\n",
      "2018-07-23 00:06:08  Training   81/1000  Loss  3.193\n",
      "2018-07-23 00:06:27  Training   83/1000  Loss  3.202\n",
      "2018-07-23 00:06:46  Training   85/1000  Loss  3.172\n",
      "2018-07-23 00:07:05  Training   87/1000  Loss  3.135\n",
      "2018-07-23 00:07:24  Training   89/1000  Loss  3.046\n",
      "2018-07-23 00:07:43  Training   91/1000  Loss  2.989\n",
      "2018-07-23 00:08:03  Training   93/1000  Loss  3.066\n",
      "2018-07-23 00:08:21  Training   95/1000  Loss  2.960\n",
      "2018-07-23 00:08:40  Training   97/1000  Loss  2.981\n",
      "2018-07-23 00:08:59  Training   99/1000  Loss  2.971\n",
      "2018-07-23 00:09:19  Training  101/1000  Loss  2.922\n",
      "2018-07-23 00:09:38  Training  103/1000  Loss  2.929\n",
      "2018-07-23 00:09:58  Training  105/1000  Loss  2.870\n",
      "2018-07-23 00:10:17  Training  107/1000  Loss  2.783\n",
      "2018-07-23 00:10:36  Training  109/1000  Loss  2.725\n",
      "2018-07-23 00:10:55  Training  111/1000  Loss  2.747\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = tc.object_detector.create(train_data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save predictions to an SArray\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Evaluate the model and save the results into a dictionary\n",
    "metrics = model.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
